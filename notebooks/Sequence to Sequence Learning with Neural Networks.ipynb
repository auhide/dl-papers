{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Learning with Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# Controlling the randomness in PyTorch\n",
    "RANDOM_SEED = 0\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Dataset\n",
    "I've used a Kaggle dataset. You can download it from [here](https://www.kaggle.com/datasets/devicharith/language-translation-englishfrench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EN</th>\n",
       "      <th>FR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     EN          FR\n",
       "0   Hi.      Salut!\n",
       "1  Run!     Cours !\n",
       "2  Run!    Courez !\n",
       "3  Who?       Qui ?\n",
       "4  Wow!  Ça alors !"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = os.path.join(\n",
    "    \"..\", \n",
    "    \"..\", \n",
    "    \"nlp\", \n",
    "    \"datasets\", \n",
    "    \"en-fr-translation\", \n",
    "    \"en-fr.csv\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "df = df.rename(columns={\"English words/sentences\": \"EN\"})\n",
    "df = df.rename(columns={\"French words/sentences\": \"FR\"})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should first download these two spaCy models!\n",
    "en_tokenizer = get_tokenizer(\"spacy\", \"en_core_web_sm\")\n",
    "fr_tokenizer = get_tokenizer(\"spacy\", \"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentence(sentence: str):\n",
    "    pattern = r\"([.,!?:;]+)\"\n",
    "    sentence = re.sub(pattern, r\" \\1 \", sentence)\n",
    "\n",
    "    pattern = r\"\\s+\"\n",
    "    sentence = re.sub(pattern, \" \", sentence)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def iterate_corpus(corpus: List[str], tokenizer: spacy.tokenizer.Tokenizer, max_len: int):\n",
    "    for sentence in corpus:\n",
    "        tokens = tokenizer(\n",
    "            prepare_sentence(sentence)\n",
    "        )\n",
    "\n",
    "        # Adding padding if it is needed.\n",
    "        if len(tokens) >= max_len:\n",
    "            tokens = tokens[:max_len]\n",
    "        else:\n",
    "            len_diff = max_len - len(tokens)\n",
    "            tokens = tokens + [\"<pad>\"] * len_diff\n",
    "\n",
    "        yield tokens\n",
    "\n",
    "\n",
    "en_corpus = [sent for sent in list(df[\"EN\"])]\n",
    "fr_corpus = [sent for sent in list(df[\"FR\"])]\n",
    "EN_MAX_LEN = 200\n",
    "FR_MAX_LEN = 200\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    iterate_corpus(en_corpus, en_tokenizer, EN_MAX_LEN), \n",
    "    specials=[\"<unk>\", \"<start>\", \"<end>\", \"<pad>\"]\n",
    ")\n",
    "en_vocab.set_default_index(en_vocab[\"<unk>\"])\n",
    "\n",
    "fr_vocab = build_vocab_from_iterator(\n",
    "    iterate_corpus(fr_corpus, fr_tokenizer, FR_MAX_LEN), \n",
    "    specials=[\"<unk>\", \"<start>\", \"<end>\", \"<pad>\"]\n",
    ")\n",
    "fr_vocab.set_default_index(fr_vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([175621, 200])\n",
      "y.shape: torch.Size([175621, 200])\n"
     ]
    }
   ],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        lang1_corpus: List[str], lang2_corpus: List[str],\n",
    "        lang1_tokenizer: spacy.tokenizer.Tokenizer, lang2_tokenizer: spacy.tokenizer.Tokenizer,\n",
    "        lang1_vocab: torchtext.vocab.Vocab, lang2_vocab: torchtext.vocab.Vocab,\n",
    "        lang1_max_len: int = 200, lang2_max_len: int = 200\n",
    "    ):\n",
    "        self.l1_corpus = lang1_corpus\n",
    "        self.l2_corpus = lang2_corpus\n",
    "\n",
    "        self.l1_max_len = lang1_max_len\n",
    "        self.l2_max_len = lang2_max_len\n",
    "        \n",
    "        self.l1_tokenizer = lang1_tokenizer\n",
    "        self.l2_tokenizer = lang2_tokenizer\n",
    "        \n",
    "        self.l1_vocab = lang1_vocab\n",
    "        self.l2_vocab = lang2_vocab\n",
    "\n",
    "        self.x, self.y = self._get_x_y()\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def _get_x_y(self):\n",
    "        x = TranslationDataset._parse_corpus(\n",
    "            self.l1_corpus, self.l1_tokenizer, self.l1_vocab, self.l1_max_len\n",
    "        )\n",
    "        y = TranslationDataset._parse_corpus(\n",
    "            self.l2_corpus, self.l2_tokenizer, self.l2_vocab, self.l2_max_len\n",
    "        )\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_corpus(\n",
    "        corpus: List[str], \n",
    "        tokenizer: spacy.tokenizer.Tokenizer, \n",
    "        vocab: torchtext.vocab.Vocab,\n",
    "        max_len: int\n",
    "    ):\n",
    "        output = []\n",
    "\n",
    "        for sent in corpus:\n",
    "            tokens = tokenizer(sent)\n",
    "            indices = [vocab[token] for token in tokens]\n",
    "            if len(indices) >= max_len:\n",
    "                output.append(indices[:max_len])\n",
    "            else:\n",
    "                len_diff = max_len - len(indices)\n",
    "                padding = [vocab[\"<pad>\"]] * len_diff\n",
    "                output.append(indices + padding)\n",
    "\n",
    "        return torch.LongTensor(output)\n",
    "\n",
    "dataset = TranslationDataset(\n",
    "    lang1_corpus=en_corpus, lang2_corpus=fr_corpus,\n",
    "    lang1_vocab=en_vocab, lang2_vocab=fr_vocab,\n",
    "    lang1_tokenizer=en_tokenizer, lang2_tokenizer=fr_tokenizer,\n",
    "    lang1_max_len=EN_MAX_LEN, lang2_max_len=FR_MAX_LEN\n",
    ")\n",
    "print(\"x.shape:\", dataset.x.shape)\n",
    "print(\"y.shape:\", dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 158058\n",
      "Validation dataset size: 17563\n"
     ]
    }
   ],
   "source": [
    "def train_validation_split(dataset: torch.utils.data.Dataset, train_size: float):\n",
    "    train_set_size = int(len(dataset) * train_size)\n",
    "    valid_set_size = len(dataset) - train_set_size\n",
    "    datasets_lengths = [train_set_size, valid_set_size]\n",
    "\n",
    "    # Splitting the input dataset into training and validation set.\n",
    "    train_dataset, valid_dataset = random_split(dataset, datasets_lengths)\n",
    "\n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "\n",
    "train_dataset, valid_dataset = train_validation_split(\n",
    "    dataset, train_size=0.9\n",
    ")\n",
    "print(\"Training dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(valid_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Seq2Seq Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: torch.Size([10, 5, 100])\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, padding_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size, padding_idx=padding_idx)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_size, \n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, hidden: tuple):\n",
    "        embedded_x = self.embed(x)\n",
    "        out, hidden = self.lstm(embedded_x, hidden)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def get_init_hidden(self, batch_size):\n",
    "        # See the PyTorch documentation of LSTM for these dimensions.\n",
    "        h = torch.Tensor(size=(self.num_layers, batch_size, self.hidden_size))\n",
    "        c = torch.Tensor(size=(self.num_layers, batch_size, self.hidden_size))\n",
    "\n",
    "        return (h, c)\n",
    "\n",
    "\n",
    "x = torch.randint(low=0, high=20, size=(10, 5))\n",
    "enc = Encoder(vocab_size=50, embed_size=100, hidden_size=100, num_layers=4, padding_idx=0)\n",
    "h, c = enc.get_init_hidden(10)\n",
    "out, hidden = enc(x, (h, c))\n",
    "print(f\"Encoder output shape: {out.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: torch.Size([10, 5, 150])\n",
      "Decoder output shape: torch.Size([10, 5, 200])\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, input_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.project(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "\n",
    "# Passing through the Encoder\n",
    "x = torch.randint(low=0, high=20, size=(10, 5))\n",
    "enc = Encoder(vocab_size=50, embed_size=100, hidden_size=150, num_layers=4, padding_idx=0)\n",
    "hidden = enc.get_init_hidden(10)\n",
    "out, hidden = enc(x, hidden)\n",
    "print(f\"Encoder output shape: {out.shape}\")\n",
    "\n",
    "# Passing through the Decoder\n",
    "dec = Decoder(vocab_size=200, input_size=150, hidden_size=150, num_layers=4)\n",
    "out, hidden = dec(out, hidden)\n",
    "print(f\"Decoder output shape: {out.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([10, 5])\n",
      "Seq2Seq output shape: torch.Size([10, 5, 200])\n",
      "Seq2Seq hidden shape: torch.Size([4, 10, 150])\n"
     ]
    }
   ],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder: torch.nn.Module, decoder: torch.nn.Module, reverse_input=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.reverse_input = reverse_input\n",
    "\n",
    "    def forward(self, x: torch.Tensor, hidden: tuple):\n",
    "        # Reversing the sequences in the input tensor.\n",
    "        # In the paper it's stated that it is 'extremely valuable', and makes a difference.\n",
    "        if self.reverse_input:\n",
    "            x = torch.flip(x, [1])\n",
    "        out, hidden = self.encoder(x, hidden)\n",
    "        out, hidden = self.decoder(out, hidden)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "\n",
    "# Input tensor:\n",
    "x = torch.randint(low=0, high=20, size=(10, 5))\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "# Defining the Encoder:\n",
    "enc = Encoder(vocab_size=50, embed_size=100, hidden_size=150, num_layers=4, padding_idx=0)\n",
    "init_hidden = enc.get_init_hidden(10)\n",
    "\n",
    "# Defining the decoder:\n",
    "dec = Decoder(vocab_size=200, input_size=150, hidden_size=150, num_layers=4)\n",
    "\n",
    "# Creating the Seq2Seq model:\n",
    "model = Seq2Seq(encoder=enc, decoder=dec)\n",
    "out, hidden = model(x, init_hidden)\n",
    "print(f\"Seq2Seq output shape: {out.shape}\")\n",
    "print(f\"Seq2Seq hidden shape: {hidden[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(model: torch.nn.Module):\n",
    "    # Initializing the weights with the uniform distribution between -0.08 and \n",
    "    # 0.08.\n",
    "    torch.nn.init.uniform_(model.weight, a=-0.08, b=0.08)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTrainingSession:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: torch.nn.Module, \n",
    "        loss: torch.nn.Module, \n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        epochs: int, l_rate: float, batch_size=int, \n",
    "        use_clipping=True,\n",
    "        device=\"cpu\"\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.loss_func = loss\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.l_rate = l_rate\n",
    "        self.batch_size\n",
    "\n",
    "        self.use_clipping = use_clipping\n",
    "        self.clip = 5\n",
    "        self.device = device\n",
    "\n",
    "    def start(\n",
    "        self, \n",
    "        train_dataset: torch.utils.data.Subset, \n",
    "        valid_dataset: torch.utils.data.Subset,\n",
    "        initial_hidden: torch.Tensor\n",
    "    ):\n",
    "        self.init_hidden = initial_hidden\n",
    "        \n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset, \n",
    "            self.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=0\n",
    "        )\n",
    "        valid_dataloader = DataLoader(\n",
    "            train_dataset, \n",
    "            self.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss = self._train_epoch(train_dataloader)\n",
    "            valid_loss = self._valid_epoch(valid_dataloader)\n",
    "            print(f\"Epoch: {epoch + 1}, Training Loss: {train_loss:.2f}, Validation Loss: {valid_loss:.2f}\")\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def _train_epoch(self, dataloader):\n",
    "        hidden = self.init_hidden\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(dataloader):\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "            y_pred, hidden = self.model(x, hidden)\n",
    "\n",
    "            loss = self.loss_func(y_pred, y)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Clipping the gradients, since LSTMs can have exploding gradients.\n",
    "            if self.use_clipping:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.model.parameters(), \n",
    "                    max_norm=self.clip\n",
    "                )\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "        epoch_loss = loss.item()\n",
    "\n",
    "        return epoch_loss\n",
    "\n",
    "\n",
    "    def _valid_epoch(self, dataloader):\n",
    "        hidden = self.init_hidden\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(dataloader):\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "            y_pred, hidden = self.model(x, hidden)\n",
    "\n",
    "            loss = self.loss_func(y_pred, y)\n",
    "\n",
    "        epoch_loss = loss.item()\n",
    "        \n",
    "        return epoch_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8100bb27ef6f27bb6b63ba202e13f32f0dffed430e6a4d162d3986e448f218b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
